install.packages("tidyverse") # коллекция пакетов от Hadley Wickham
install.packages("lmtest") # тесты в линейных моделях
install.packages("sandwich") # оценки ковариационной матрицы робастные к гетероскедастичности
install.packages("erer") # подборка пакетов для эмпирических исследований
install.packages("estimatr") # модели с робастными стандартными ошибками
install.packages("GGally") # матрица диаграмм рассеяния
install.packages("lattice") # конкурент ggplot2
install.packages("vcd") # мозаичный график
install.packages("hexbin") # график из шестиугольников
install.packages("sjPlot") # визуализация результатов МНК
install.packages("factoextra") # визуализация для метода главных компонент и не только
install.packages("reshape2") # длинные <-> широкие таблицы
install.packages("psych") # описательные статистики
install.packages("skimr") # описательные статистики
install.packages("HSAUR")
install.packages("sgof")
install.packages("car") # для тестирования линейных гипотез, подсчёта vif
install.packages("spikeslab") # байесовская регрессия пик-плато
install.packages("quantreg") # квантильная регрессия
install.packages("MCMCpack") # набор моделей с байесовским подходом
install.packages("devtools") # разработка пакетов
install.packages("caret") # подбор параметров с помощью кросс-валидации
install.packages("AER")
install.packages("ivpack") # интсрументальные переменные
install.packages("zoo") # нерегулярные временные ряды
install.packages("xts") # еще ряды
install.packages("forecast") # ARMA, экспоненциальное сглаживание
install.packages("rugarch") # не используется в курсе, хорош для GARCH
install.packages("quantmod") # загрузка с finance.google.com
install.packages("Quandl") # загрузка с Quandl
install.packages("sophisthse") # read data from sophist.hse.ru

library(tidyverse) 
library(mfx) 
library(rio) 
library(texreg) 

set.seed(0)

data = import("C:/Users/pvkuz/Desktop/country_profile_variables.csv")

#Часть 1: Вперёд и с песней!
#Задание 1: 
#Сформулируем исследовательский вопрос: Я хочу изучить, как связаны темпы экономического роста (ВВП) и внешнеэкономическая деятельность страны(экспорт), плотность населения, уровень рождаемости и уровень безработицы. Для этого в качестве объясняемой переменной возьмём логарифм ВВП.   
#Задание 2: 
#Объясняющие переменные
#В качестве непрерывных и нелинейных переменных возьмём экспорт и уровень рождаемости:
#Выбор экспорта в качестве зависимой переменной объясняется тем, что чем больше страна вовлечена во внешнюю торговлю, тем больший денежный доход она получает на мировой арене, и тем выше ВВП => ожидаемый эффект - положительный
#Уровень рождаемости отражается на населении страны. В развитых странах с высокими темпами роста ВВП наблюдается тенденция сокращения уровня рождаемости, в развивающихся же наоборот => ожидаемый эффект - отрицательный
#В качестве бинарных переменных возьмём плотность населения и уровень безработицы:
#Дамми-переменная плотности населения = 1, если значение переменной > 150 (густонаселённая страна), 0, иначе. Более густонаселённые страны характеризуются меньшими темпами роста ВВП. В списке самых густонаселённых стран преобладают развивающиеся страны иболее отсталые => ожидаемый эффект - отрицательный
#Дамми-переменная уровня безработицы = 1, если значение переменной > 7% (высокий уровень безработицы), 0, иначе. Чем выше уровень безработицы, тем ниже покупательная способность населения, и покупательный спрос сокращается => ожидаемый эффект - отрицательный
#Посмотрим на данные, видно, что названия переменных слишком длинные, нужно переименовать и сделать их покороче для удобства работы
summary(data)
#Для этого посмотрим, в каком столбце какая переменная находится, этот способ наиболее простой, так как выборка большая и искать в таблице нужные пееременные очень долго
colnames(data)
#Переобозначим выбранные переменные
names(data)[7] <- "GDP"
names(data)[20] <- "export"
names(data)[27] <- "fertility"
names(data)[5] <- "p_density"
names(data)[16] <- "unempl"
names(data)[35] <- "educ_exp"

#Преобразуем и почистим данные
#Там, где у нас есть пропущенные значения в данных, заполним пропсуи средними значениями переменной, переменные, которые мы ходим сделать дамми, почистим от выбросов сразу, до того, как создадим дамми-переменную, остальные - чуть позже
#Преобразуем экспорт в чсиловую переменную
export_n = as.numeric(data$export)
data$export = export_n

#Уберём отрицательные значения
data$GDP[data$GDP == -99]<- NA
data$p_density[data$p_density > 1500]<- NA
data$export[data$export == -99]<- NA
data$fertility[data$fertility == -99]<- NA
data$unempl[data$unempl == -99]<- NA
#Теперь заполняем пропуски: для этого сначала меняем NA на 0, затем считаем среднее значение для каждой переменной и заполняем 0 средними

#Для экспорта
data$export[is.na(data$export)] = 0
data$export = as.numeric(data$export)
b = mean(data$export)
data$export[data$export == 0] = b
hist(data$export)
mean(data$export)

#Для плотности населения
data$p_density[is.na(data$p_density)] = 0
data$p_density = as.numeric(data$p_density)
d = mean(data$p_density)
data$p_density[data$p_density == 0] = d
hist(data$p_density)
mean(data$p_density)

data$p_density[data$p_density > 1000]<- NA
na.omit("p_density")

#Для уровня рождаемости
data$fertility[is.na(data$fertility)] = 0
data$fertility = as.numeric(data$fertility)
data$fertility[is.na(data$fertility)] = 0
e = mean(data$fertility)
data$fertility[data$fertility == 0] = e
hist(data$fertility)
mean(data$fertility)

#Для безработицы
data$unempl[is.na(data$unempl)] = 0
data$unempl = as.numeric(data$unempl)
data$unempl[is.na(data$unempl)] = 0
f = mean(data$unempl)
data$unempl[data$unempl == 0] = f
hist(data$unempl)
mean(data$unempl)
data$unempl[data$unempl > 30]<- NA
na.omit("unempl")

#Создадим необходимые переменные от уже имеющихся
lnGDP = log(data$GDP)
data <- data.frame(lnGDP, data)

p_density_dummy <- NULL
p_density_dummy[data$p_density < 150] = 0
p_density_dummy[data$p_density > 150] = 1
data <- data.frame(p_density_dummy, data)

unempl_dummy <- NULL
unempl_dummy[data$unempl < 7] = 0
unempl_dummy[data$unempl > 7] = 1
data <- data.frame(unempl_dummy, data)

#Задание 3 (данные были частично почищены ранее, здесь приведём более красивые гистограммы после борьбы с пропусками данных и очистки от выбросов, а также сдалаем оставшиеся преобразования)

install.packages("ggplot2")
library(ggplot2)

#Гистограмма для переменной уровень рождаемости
hist(data$fertility, breaks = 20, freq = FALSE, col = "red",
     xlab = "Уровень рождаемости",
     ylab = "Плотность вероятности",
     main = "Распределение уровня рождаемости")

#Гистограмма для переменной экспорт
hist((as.numeric(data$export)), breaks = 20, freq = FALSE, col = "pink",
     xlab = "Экспорт",
     ylab = "Плотность вероятности",
     main = "Распределение экспорта (млн$)")

#Чистим эти две переменные от выбросов
data$fertility[data$fertility > 6]<- NA
na.omit("fertility")

data$export[data$export > 10000]<- NA
na.omit("export")

#Задание 4:
#Запишем спецификацию нашей модели
m1 = lm(data$lnGDP~data$p_density_dummy+data$unempl_dummy + data$export + data$fertility, data= data)
#Проверка на мультиколинеарность
#Построим корреляционную матрицу
X = model.matrix(~0 + data$p_density_dummy + data$unempl_dummy +  data$export +   data$fertility, data= data)
cor(X)
#Теперь посчитаем VIF
library("car")
vif(m1)
#Посмотрим ещё на CN(Condition Number)
install.packages("olsrr")
library(olsrr)
ols_coll_diag(m1)
#Вывод:в нашей модели нет мультиколинеарности: VIF везде чуть больше 1 (то есть значительно меньше 10), CN = 8.28< 30

#Теперь проверим на наличие гетероскедастичности. Есть много различных тестов, возьмём, например, тест Бройша-Пагана и тесть Голдфельда-Квандта
install.packages("lmtest")
library(lmtest)
#Тест Бройша-Пагана
bptest(m1)
#В нашем случае p-value(0.2763) > alpha => H0 не отвергается => гетероскедастичность не наблюдается

#Чтобы провести GQ тест, надо сделать предположение о гетероскедастичности какой-нибудь переменной
qplot(data = data, export, log(GDP), main = "Is export hetero?")
qplot(data = data, fertility, log(GDP), main = "Is fertility hetero?")
#Подозреваем уровень рождаемости на гетероскедастичность
#Отфильтруем по уровню рождаемости
GQ <- data[order(data$fertility), ] 
m2 <- lm(lnGDP ~ fertility, data = GQ) 
#Проведем GQ тест, выкинув посередине 20% наблюдений
gqtest(m2, fraction = 0.2) 
#В нашем случае p-value(0.6178) > alpha => H0 не отвергается => гетероскедастичность не наблюдается
#Ура!

#Задание 5:
#(а) Оценим модель спомощью МНК ещё раз
m1 = lm(data$lnGDP~data$p_density_dummy+data$unempl_dummy + data$export + data$fertility, data= data)
summary(m1)
#Свободный член положителен и равен 7.84
#Плотность населения и экспорт значимы, очень маленькие p-value
#Экспорт и уровень рождаемости положитеьно влияют на ВВП, а густая плотность населения и высокий уровень безработицы отрицательно, что в целом совпадает с выдвинутыми предположениями в началле работы
#При увеличении экспорта на 1 денежную единицу, ВВП увеличится на 0,004%)
#При увеличении уровня рождаемости на 1, ВВП увеличится на 0,03%)

#Регрессия является адекватной, p-value очень маленькое

#(б) Оценим модель спомощью 2-хшагового МНК
# двухшаговый МНК в одну строчку
install.packages("ivpack")
library(ivpack)
#Что-то не получилось((
#Ну ничего! Попробуем побороть 6 задачу!

#Задание 6:
#Есть зависимая переменная из п.1 и регрессор из п.2
#Базовая модель: Y = Xb + u - оцениваем с помощью МНК
#разделим выборку на обучающую и тестовую в соотношении 80%/20%
library(caret)
train <-createDataPartition(y=data$GDP.growth.rate..annual....const..2005.prices., p=0.8, list=FALSE)
train_part <- data[train, ]
test_part <- data[-train, ]

#Обучим изначальную модель МНК
m_1 <- lm(lnGDP~data$p_density_dummy+data$unempl_dummy + data$export + data$fertility, data$train_part)
ls <- seq(50, 0.1, lenght = 222)
y <- data$lnGDP
x <- model.matrix(data=train_part, lnGDP~0+data$p_density_dummy+data$unempl_dummy + data$export + data$fertility)
#И опять что-то пошло не так, хны((

#Часть 2: Табалуга и река времени

install.packages("forecast") 
install.packages("fable") 

#Попробуем решить!

#Задание 1:
#Дано: n1=n2=n3=120, AR(1), AR(3), MA(2)
#Рассмотрим каждое уравнени по отдельности 

#1
#Запишем спецификацию модели AR(1):
y_1 = arima.sim(n=120, list(ar=0.8))
#Построим график для AR(1):
plot(y_1, xlab = "t", ylab = "y(t)", main = "График для AR(1)")
#Является ли этот ряд стационарным?
#Мы можем легко проверить это: из куса эконометрики мы знаем, что для проверки временного ряда необходимо найти корни характеристического уравнения, в данном случае корень один и равен 0.8 < 1 => ряд стационарен
#Можем также оценить это визуально. Для того чтобы ряд был стационарным, необходимо выполнение следующих условий: постоянное матожидание E(X(t))=const, Var(X(t))=sigma^2 и cov(X(t), X(t+s))=a(s) не зависит от t, может зависеть только от s => условия в целом выполняются с визуальной точки зрения

#2
#Запишем спецификацию модели AR(3):
y_2 = arima.sim(n=120, list(ar = c(0.1, 0.2, 0.3)))
#Построим график для AR(3):
plot(y_2, xlab = "t", ylab = "y(t)", main = "График для AR(3)")
#Является ли рядстационарным?
#Аналитически: корни характеристического уравнения, в данном случае корени -0.35=-0.496i, выделив действительную часть, получим корни < 1 => ряд стационарен
#Аналитически: аналогично предыдущему ряду => стационарный

#3
#Запишем спецификацию модели MA(2):
y_3 = arima.sim(n=120, list(ma = c(1.2, 2)))
#Построим график для MA(2):
plot(y_3, xlab = "t", ylab = "y(t)", main = "График для MA(2)")
#Является ли ряд стационарным?
#MA процесс в любом случае является стационарным, это мы знаем, но можем и проверить аналитически, получим комплексные числа -0.6+-1.28i, выделим действительную часть, которая будет < 1, графчески это тоже видно => стационарен

#Задание 2:

#1
#Сгенерируем ряд ARIMA(0,1,2)
y_4=arima.sim(n=120, list(order = c(0,1,2), ma = c(1.2,2)))
#Построим график для ARIMA(0,1,2):
plot(y_4, xlab = "t", ylab = "y(t)", main = "График для ARIMA(0,1,2)")
#Является ли ряд стационарным?
#Ответ: нет, так как матожидание непостоянно на временном горизонте, зависит от t. Можно сделать стационарным, взяв разность порядка d.

#2
#Сгенерируем  ряд ARIMA(0,0,0)
y_5=arima.sim(n=120, list(order = c(0,0,0)))
#Построим график для ARIMA(0,0,0):
plot(y_5, xlab = "t", ylab = "y(t)", main = "График для ARIMA(0,0,0)")
#Является ли стационарным?
#Ответ: да, так как белый шум

#3
#Сгенерируем  ряд ARIMA(3,0,0)
y_6=arima.sim(n=120, list(order = c(3,0,0), ar = c(0.1,0.2,0.3)))
#Построим график для ARIMA(3,0,0):
plot(y_6, xlab = "t", ylab = "y(t)", main = "График для ARIMA(3,0,0)")
#Является ли стационарным?
#Ответ: да, ~ AR(3)

#Задание 3:
#Уравнение случайного блуждания без дрейфа: y(t) = y(t-1) + e(t)
#Сгенерируем этот временной ряд
y_7 = arima.sim(n=120, list(order = c(0,1,0)))
#Построим график для уравнения случайного блуждания:
plot(y_7, xlab = "t", ylab = "y(t)", main = "График для уравнения случайного блуждания")
#Является ли стационарным?
#Ответ: нет так как матожидание непостоянно во времени

#Задание 4:
#AR(1): это превое уравнение системы y(t) = 0.8y(t-1) + e(t)
#Запишем ACF для AR(1):
acf(y_1, main = "Автокорреляционная функция для AR(1)")
pacf(y_1, main = "Частная автокорреляционная функция для AR(1)")
#Построим графики ACF для AR(1) убывает с увеличением лага, уже начиная с 6 лага входит в зону незначимости (близкую к нулю), затем вновь слегка выходит за её пределы, чем в принципе можно пренебречь, и при более высоких значениях лага окончательно становится незначимым.
#Для PACF процесса AR(1) мы видим только один огромный лаг на первом шаге, дальше всё хорошо, входит в зону невначимости.

#Чтобы сравнить с результатами ACF и PACF случайного блуждания, надо их вычислить - сделаем это!
acf(y_7, main = "Автокорреляционная функция для урвнения случайного блуждания")
pacf(y_7, main = "Автокорреляционная функция для уравнения случайного блуждания")
#График ACF для процесса случайног облуждания схож с аналогичным для AR(1) лишь тем, что постепенно убывает при увеличении лага, однако это происходит намного  позднее, начиная лишь после 10 лага.
#PACF для процесса случайного блуждания очень схож с AR(1), наблюдаем аналогичную картину.

#Задание 5:
#Сгенерируем ряд для ARIMA(2,0,3), n=120
#Пусть коэффициенты для AR(2) части будут -0.2 и 0.2, напрмер, а для MA(3) 0.3, 0.2 и 0.1
#Теперь сгенерируем сам ряд:
y_8 = arima.sim(n = 120, list(order = c(2,0,3), ar = c(0.2, -0.2), ma = c(0.3, 0.2, 0.1)))
plot(y_8, xlab = "t", ylab = "y(t)", main = "График для ARIMA(2,0,3")
#Обучающая выборка из 100 наблюдений - первая часть, тестовая выборка из 20 наблюдений - вторая часть
ytrain = y_8[1:100]
ytest = y_8[101:120]
#Теперь оцениваем модель ARIMA(2, 0, 3) на обучающей выборке
m <- arima(ytrain, order = c(2, 0, 3))
summary(m)
AIC(m)
#Построим прогноз на 20 шагов вперёд
forecast_20 <- predict(m, n.ahead = 20)
forecast_20
#Графическая иллюстрация
t=c(101:120)
plot(t, ytest, xlab="t", ylab="y(t)", main="ARIMA(2,0,3) с фактическими значениями и прогнозами", ylim=c(-30,30))

#На этом всё :) Спасибо за задания! Было интересно, хоть и дорстаточно трудно местами, но благодаря этому я узнала много нового и немного научилась работать в R :)

